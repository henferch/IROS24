\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Newen2018}
\citation{siposova2019}
\citation{chame2023top}
\citation{albus1991}
\citation{amari1977}
\@writefile{toc}{\contentsline {section}{\numberline {I}INTRODUCTION}{1}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The scene shows a situation where two agents are interacting about the orange object while a third agent is leaving the scene. Three other objects are present. The effect of stimuli projection in agents’ peripersonal is represented at a pre-selection level of attention in ego-spherical localization.}}{1}{figure.1}\protected@file@percent }
\newlabel{fig:multi_robots}{{1}{1}{The scene shows a situation where two agents are interacting about the orange object while a third agent is leaving the scene. Three other objects are present. The effect of stimuli projection in agents’ peripersonal is represented at a pre-selection level of attention in ego-spherical localization}{figure.1}{}}
\newlabel{fig:multi_robots@cref}{{[figure][1][]1}{[1][1][]1}}
\citation{albus1991}
\citation{ruesch2008}
\citation{bodiroza2011}
\citation{peters2009sensory}
\citation{grotz2017}
\citation{marques2022}
\citation{ruesch2008}
\citation{heikkila2019}
\citation{belhassein2022}
\citation{sallami2019}
\citation{chame2016}
\citation{chame2023top}
\citation{treisman1980}
\citation{koch1985}
\citation{itti1998}
\citation{siagian2014}
\@writefile{toc}{\contentsline {section}{\numberline {II}PREVIOUS WORK}{2}{section.2}\protected@file@percent }
\newlabel{sec:previous}{{II}{2}{PREVIOUS WORK}{section.2}{}}
\newlabel{sec:previous@cref}{{[section][2][]II}{[1][2][]2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}THE MATHEMATICAL MODEL}{2}{section.3}\protected@file@percent }
\newlabel{sec:model}{{III}{2}{THE MATHEMATICAL MODEL}{section.3}{}}
\newlabel{sec:model@cref}{{[section][3][]III}{[1][2][]2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The model AEGO takes as inputs rough estimations on the objects' locations with respect to egocentric frames of reference, proprioceptive and basic natural language inputs. This information excites the attention pre-selection layer $\mathbf  {u}$ (see Eq. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:pre-sel}\unskip \@@italiccorr )}}), which provides input to the selection layer $\mathbf  {a}$ (see Eq. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:sel}\unskip \@@italiccorr )}}). In layer $\mathbf  {k}$ (see Eq. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:out}\unskip \@@italiccorr )}}) the model outputs the probability of focusing on a particular stimulus. Under top-down modulation, focused attention can influence pre-selection as a feedback process.}}{2}{figure.2}\protected@file@percent }
\newlabel{fig:AEGO}{{2}{2}{The model AEGO takes as inputs rough estimations on the objects' locations with respect to egocentric frames of reference, proprioceptive and basic natural language inputs. This information excites the attention pre-selection layer $\mathbf {u}$ (see Eq. \eqref {eq:pre-sel}), which provides input to the selection layer $\mathbf {a}$ (see Eq. \eqref {eq:sel}). In layer $\mathbf {k}$ (see Eq. \eqref {eq:out}) the model outputs the probability of focusing on a particular stimulus. Under top-down modulation, focused attention can influence pre-selection as a feedback process}{figure.2}{}}
\newlabel{fig:AEGO@cref}{{[figure][2][]2}{[1][2][]2}}
\citation{samsonovich97}
\citation{schoner2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}Pre-attention phase}{3}{subsection.3.1}\protected@file@percent }
\newlabel{eq:pre-sel}{{1}{3}{Pre-attention phase}{equation.3.1}{}}
\newlabel{eq:pre-sel@cref}{{[equation][1][]1}{[1][3][]3}}
\newlabel{eq:pre-sel-syn}{{2}{3}{Pre-attention phase}{equation.3.2}{}}
\newlabel{eq:pre-sel-syn@cref}{{[equation][2][]2}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Attention selection phase}{3}{subsection.3.2}\protected@file@percent }
\newlabel{eq:sel}{{3}{3}{Attention selection phase}{equation.3.3}{}}
\newlabel{eq:sel@cref}{{[equation][3][]3}{[1][3][]3}}
\newlabel{eq:sel-syn}{{4}{3}{Attention selection phase}{equation.3.4}{}}
\newlabel{eq:sel-syn@cref}{{[equation][4][]4}{[1][3][]3}}
\newlabel{eq:sel-fa}{{5}{3}{Attention selection phase}{equation.3.5}{}}
\newlabel{eq:sel-fa@cref}{{[equation][5][]5}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-C}Object focus output layer}{3}{subsection.3.3}\protected@file@percent }
\newlabel{eq:out}{{6}{3}{Object focus output layer}{equation.3.6}{}}
\newlabel{eq:out@cref}{{[equation][6][]6}{[1][3][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}METHODOLOGY}{3}{section.4}\protected@file@percent }
\newlabel{sec:methodology}{{IV}{3}{METHODOLOGY}{section.4}{}}
\newlabel{sec:methodology@cref}{{[section][4][]IV}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Materials and Resources}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Simulations}{3}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Common parameters for simulations}}{3}{table.1}\protected@file@percent }
\newlabel{tab:params}{{I}{3}{Common parameters for simulations}{table.1}{}}
\newlabel{tab:params@cref}{{[table][1][]I}{[1][3][]3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Bottom-up stimulation at six locations in the sensory ego-space. The objects' estimated center of mass coordinates $\mathbf  {p}_i$ and projection $\mathbf  {\hat  {p}}_i$ on the ego-sphere are shown. To improve visualization, the frame of reference located at the ego-sphere's center is shown at bottom-right.}}{4}{figure.3}\protected@file@percent }
\newlabel{fig:sim_objs}{{3}{4}{Bottom-up stimulation at six locations in the sensory ego-space. The objects' estimated center of mass coordinates $\mathbf {p}_i$ and projection $\mathbf {\hat {p}}_i$ on the ego-sphere are shown. To improve visualization, the frame of reference located at the ego-sphere's center is shown at bottom-right}{figure.3}{}}
\newlabel{fig:sim_objs@cref}{{[figure][3][]3}{[1][3][]4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {IV-B.1}Focusing on named objects}{4}{subsubsection.4.2.1}\protected@file@percent }
\newlabel{eq:sim1}{{7}{4}{Focusing on named objects}{equation.4.7}{}}
\newlabel{eq:sim1@cref}{{[equation][7][]7}{[1][4][]4}}
\newlabel{eq:sim1-step}{{8}{4}{Focusing on named objects}{equation.4.8}{}}
\newlabel{eq:sim1-step@cref}{{[equation][8][]8}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {IV-B.2}Searching around objects}{4}{subsubsection.4.2.2}\protected@file@percent }
\newlabel{eq:sim2}{{9}{4}{Searching around objects}{equation.4.9}{}}
\newlabel{eq:sim2@cref}{{[equation][9][]9}{[1][4][]4}}
\newlabel{eq:sim2-mu}{{10}{4}{Searching around objects}{equation.4.10}{}}
\newlabel{eq:sim2-mu@cref}{{[equation][10][]10}{[1][4][]4}}
\newlabel{eq:sim2-m}{{11}{4}{Searching around objects}{equation.4.11}{}}
\newlabel{eq:sim2-m@cref}{{[equation][11][]11}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {IV-B.3}Losing interest on something}{4}{subsubsection.4.2.3}\protected@file@percent }
\newlabel{eq:sim3}{{12}{4}{Losing interest on something}{equation.4.12}{}}
\newlabel{eq:sim3@cref}{{[equation][12][]12}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}Experiment}{4}{subsection.4.3}\protected@file@percent }
\newlabel{eq:hebb_rule}{{13}{5}{Experiment}{equation.4.13}{}}
\newlabel{eq:hebb_rule@cref}{{[equation][13][]13}{[1][5][]5}}
\newlabel{eq:hebb_stim}{{14}{5}{Experiment}{equation.4.14}{}}
\newlabel{eq:hebb_stim@cref}{{[equation][14][]14}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {V}RESULTS}{5}{section.5}\protected@file@percent }
\newlabel{sec:results}{{V}{5}{RESULTS}{section.5}{}}
\newlabel{sec:results@cref}{{[section][5][]V}{[1][5][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Operators described in the simulation scenario \textit  {searching around objects}. The top-down modulation of attention is shown after instantaneous recognition of the words \textit  {left}, \textit  {right}, \textit  {above}, and \textit  {below} see (Eq. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:sim2}\unskip \@@italiccorr )}}), relative to the location $\mathbf  {\hat  {p}}_3$ in Fig. \ref  {fig:sim_objs}).}}{5}{figure.4}\protected@file@percent }
\newlabel{fig:sim2}{{4}{5}{Operators described in the simulation scenario \textit {searching around objects}. The top-down modulation of attention is shown after instantaneous recognition of the words \textit {left}, \textit {right}, \textit {above}, and \textit {below} see (Eq. \eqref {eq:sim2}), relative to the location $\mathbf {\hat {p}}_3$ in Fig. \ref {fig:sim_objs})}{figure.4}{}}
\newlabel{fig:sim2@cref}{{[figure][4][]4}{[1][5][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Focusing initially on object 3 (relative to $\mathbf  {\hat  {p}}_3$, see Fig. \ref  {fig:sim_objs}), the agent switches attention to surrounding objects, from instantaneous recognition of words in the sequence: \textit  {right}, \textit  {above}, \textit  {left}, \textit  {left} and \textit  {below} (see Eqs. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:sim2}\unskip \@@italiccorr )}}\textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:sim2-m}\unskip \@@italiccorr )}}).}}{5}{figure.5}\protected@file@percent }
\newlabel{fig:sim2-around}{{5}{5}{Focusing initially on object 3 (relative to $\mathbf {\hat {p}}_3$, see Fig. \ref {fig:sim_objs}), the agent switches attention to surrounding objects, from instantaneous recognition of words in the sequence: \textit {right}, \textit {above}, \textit {left}, \textit {left} and \textit {below} (see Eqs. \eqref {eq:sim2}\eqref {eq:sim2-m})}{figure.5}{}}
\newlabel{fig:sim2-around@cref}{{[figure][5][]5}{[1][5][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Landmarks stickers tracked by the robot were attached to locations in the room emulating objects.}}{5}{figure.6}\protected@file@percent }
\newlabel{fig:exp_scene}{{6}{5}{Landmarks stickers tracked by the robot were attached to locations in the room emulating objects}{figure.6}{}}
\newlabel{fig:exp_scene@cref}{{[figure][6][]6}{[1][5][]5}}
\bibstyle{acm}
\bibdata{references}
\bibcite{albus1991}{1}
\bibcite{amari1977}{2}
\bibcite{belhassein2022}{3}
\bibcite{bodiroza2011}{4}
\bibcite{chame2016}{5}
\bibcite{chame2023top}{6}
\bibcite{grotz2017}{7}
\bibcite{heikkila2019}{8}
\bibcite{itti1998}{9}
\bibcite{koch1985}{10}
\bibcite{marques2022}{11}
\bibcite{Newen2018}{12}
\bibcite{peters2009sensory}{13}
\bibcite{ruesch2008}{14}
\bibcite{sallami2019}{15}
\bibcite{samsonovich97}{16}
\bibcite{schoner2016}{17}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The instantaneous state of $\mathbf  {a}_{\mathrm  {h}(t)}$ representing the human focus of attention at time $t$ stimulates the robot's pre-selection layer $\mathbf  {u}_{\mathrm  {r}(t)}$ conforming to Eq. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:hebb_stim}\unskip \@@italiccorr )}}. Although variability due to the human positioning was present, the attention state of the human, modulated by intersecting his/her forearms' direction when pointing with the ego-sphere was able to modulate the robot's attention for all experiential trials, from one single learning trial.}}{6}{figure.7}\protected@file@percent }
\newlabel{fig:exp_hebb}{{7}{6}{The instantaneous state of $\mathbf {a}_{\mathrm {h}(t)}$ representing the human focus of attention at time $t$ stimulates the robot's pre-selection layer $\mathbf {u}_{\mathrm {r}(t)}$ conforming to Eq. \eqref {eq:hebb_stim}. Although variability due to the human positioning was present, the attention state of the human, modulated by intersecting his/her forearms' direction when pointing with the ego-sphere was able to modulate the robot's attention for all experiential trials, from one single learning trial}{figure.7}{}}
\newlabel{fig:exp_hebb@cref}{{[figure][7][]7}{[1][5][]6}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}CONCLUSIONS}{6}{section.6}\protected@file@percent }
\newlabel{sec:conclusions}{{VI}{6}{CONCLUSIONS}{section.6}{}}
\newlabel{sec:conclusions@cref}{{[section][6][]VI}{[1][5][]6}}
\@writefile{toc}{\contentsline {section}{References}{6}{section*.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The ego-spheres are shown for the robot (left) and the human (center, rotated 160° around the $z$ axis to improve visualization). The human skeleton is tracked from the robot's camera (right). Each row corresponds to pointing at a given landmark. After the Hebbian learning phase, the human pointing at gesture stimulates locations in the robot's ego-sphere which relate to saliency around landmarks locations, helping the robot to focus attention on such objects.}}{6}{figure.8}\protected@file@percent }
\newlabel{fig:exp_frames}{{8}{6}{The ego-spheres are shown for the robot (left) and the human (center, rotated 160° around the $z$ axis to improve visualization). The human skeleton is tracked from the robot's camera (right). Each row corresponds to pointing at a given landmark. After the Hebbian learning phase, the human pointing at gesture stimulates locations in the robot's ego-sphere which relate to saliency around landmarks locations, helping the robot to focus attention on such objects}{figure.8}{}}
\newlabel{fig:exp_frames@cref}{{[figure][8][]8}{[1][5][]6}}
\bibcite{siagian2014}{18}
\bibcite{siposova2019}{19}
\bibcite{treisman1980}{20}
